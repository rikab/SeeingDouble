{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 15:14:29.919959: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-19 15:14:29.919984: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Architectures'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/n/home01/rikab/SeeingDouble/make_plots.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67696e2e72632e6661732e686172766172642e656475222c2275736572223a2272696b6162227d/n/home01/rikab/SeeingDouble/make_plots.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mGaussianAnsatz\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m build_gaussianAnsatz_DNN, build_gaussianAnsatz_EFN, build_gaussianAnsatz_PFN, determine_constant\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67696e2e72632e6661732e686172766172642e656475222c2275736572223a2272696b6162227d/n/home01/rikab/SeeingDouble/make_plots.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Extra utils\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67696e2e72632e6661732e686172766172642e656475222c2275736572223a2272696b6162227d/n/home01/rikab/SeeingDouble/make_plots.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mJEC\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mJEC_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_data\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67696e2e72632e6661732e686172766172642e656475222c2275736572223a2272696b6162227d/n/home01/rikab/SeeingDouble/make_plots.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mGaussianAnsatz\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_MI\n",
      "File \u001b[0;32m~/SeeingDouble/JEC/JEC_utils.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mGaussianAnsatz\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m join_models\n\u001b[1;32m     18\u001b[0m \u001b[39m# IFN Architectures\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mArchitectures\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdnn\u001b[39;00m \u001b[39mimport\u001b[39;00m DNN\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mArchitectures\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mifn\u001b[39;00m \u001b[39mimport\u001b[39;00m IFN, GaussianAnsatz\n\u001b[1;32m     22\u001b[0m \u001b[39m# Energy-flow package for CMS Open Data loader\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Architectures'"
     ]
    }
   ],
   "source": [
    "# Standard stuff\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "import os, sys\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "\n",
    "# ML stuff\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Input, Concatenate, LeakyReLU\n",
    "import tensorflow as tf\n",
    "\n",
    "# IFN Architectures\n",
    "# from GaussianAnsatz.Architectures.dnn import DNN\n",
    "from GaussianAnsatz.archs import GaussianAnsatz\n",
    "from GaussianAnsatz.archs import mine_loss, regulated_mine_loss, joint, marginal, MI\n",
    "from GaussianAnsatz.utils import build_gaussianAnsatz_DNN, build_gaussianAnsatz_EFN, build_gaussianAnsatz_PFN, determine_constant\n",
    "\n",
    "\n",
    "# Extra utils\n",
    "from JEC.JEC_utils import load_data\n",
    "from GaussianAnsatz.utils import plot_MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dim = 1\n",
    "x_dim = 3\n",
    "loadfile = None\n",
    "dnn_loadfile = \"Models/DNN.hdf5\"\n",
    "efn_loadfile = \"Models/EFN.hdf5\"\n",
    "pfn_loadfile = \"Models/PFN.hdf5\"\n",
    "pfn_pid_loadfile = \"Models/PFN_PID.hdf5\"\n",
    "cache_dir = \"/n/holyscratch01/iaifi_lab/rikab/.energyflow\"\n",
    "\n",
    "colors = ['red', 'yellow', 'green', 'blue', \"purple\"]\n",
    "labels = ['DNN', \"EFN\", \"PFN\", \"PFN-PID\", \"CMS\"]\n",
    "\n",
    "# Dataset Parameters\n",
    "momentum_scale = 1000\n",
    "n = 2500\n",
    "pad = 150\n",
    "pad_EFN = 150\n",
    "pad_PFN = 150\n",
    "pt_lower, pt_upper = 695, 705\n",
    "eta = 2.4\n",
    "quality = 2\n",
    "epochs = 150\n",
    "d_multiplier = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################\n",
    "# ########## DATASET ##########\n",
    "# #############################\n",
    "\n",
    "X_test, PFCs_test, Y_test, C_test, N_test = load_data(cache_dir, pt_lower, pt_upper, eta, quality, pad, x_dim = 4, momentum_scale = momentum_scale, n = n, max_particle_select = 150)\n",
    "test = (X_test, PFCs_test, Y_test, C_test)\n",
    "\n",
    "\n",
    "plt.hist(N_test, bins=25, histtype = 'step', color = \"red\", label = \"# of Particles\", density=True)\n",
    "plt.xlabel(r\"$N$\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(r\"Particle Count\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############################\n",
    "# ########## MODELS ##########\n",
    "# ############################\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "# print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "# with strategy.scope():\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "DNN = build_gaussianAnsatz_DNN(x_dim, y_dim, [64, 64, 64], opt = opt)\n",
    "EFN = build_gaussianAnsatz_EFN(x_dim, y_dim, (100, 100, 128, ), (100, 100, 100, ), LeakyReLU(), pad_EFN, loadfile = efn_loadfile, d_multiplier = d_multiplier, opt = opt)\n",
    "PFN = build_gaussianAnsatz_PFN(x_dim, y_dim, (100, 100, 128, ), (100, 100, 100, ), LeakyReLU(),loadfile = pfn_loadfile, d_multiplier = d_multiplier, opt = opt)\n",
    "PFN_pid = build_gaussianAnsatz_PFN(x_dim + 1, y_dim, (100, 100, 128, ), (100, 100, 100, ), LeakyReLU(), loadfile = pfn_pid_loadfile, d_multiplier = d_multiplier, opt = opt)\n",
    "\n",
    "# DNN loading is weird:\n",
    "DNN.pre_train([X_test[:100],Y_test[:100]], epochs = 1, batch_size= 2, verbose = False)\n",
    "DNN.load_weights(dnn_loadfile)\n",
    "\n",
    "\n",
    "def dnn_predict(test, model, c = 0):\n",
    "\n",
    "    yhat, sigma, T, MI = DNN.eval(test[0], test[2], loss = joint, c = c)\n",
    "    return yhat * momentum_scale, sigma * momentum_scale, T, MI\n",
    "\n",
    "def efn_predict(test, model, c = 0):\n",
    "    yhat, sigma, T, MI = EFN.eval(test[1][:,:,:3], test[2], loss = joint, c = c)\n",
    "    return yhat * momentum_scale, sigma * momentum_scale, T, MI\n",
    "\n",
    "def pfn_predict(test, model, c = 0):\n",
    "    yhat, sigma, T, MI = model.eval(test[1][:,:,:3], test[2], loss = joint, c = c)\n",
    "    return yhat * momentum_scale, sigma * momentum_scale, T, MI\n",
    "\n",
    "def pfn_pid_predict(test, model, c = 0):\n",
    "\n",
    "    yhat, sigma, T, MI = model.eval(test[1], test[2], loss = joint, c = c)\n",
    "    return yhat * momentum_scale, sigma * momentum_scale, T, MI\n",
    "\n",
    "def cms_predict(test, model, c = 0):\n",
    "    x = test[0]\n",
    "    pt = x[:,0]\n",
    "    yhat = momentum_scale * np.multiply(pt, test[3])\n",
    "    jer = np.sqrt( 30/yhat**2 + 0.81/yhat + 0.04**2   )\n",
    "    return yhat, np.multiply(yhat, jer), np.zeros_like(yhat), 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from GaussianAnsatz.utils import plot_MI\n",
    "\n",
    "# # Mutual Information plots\n",
    "# names = [\"DNN\", \"EFN\", \"PFN\", \"PFN_PID\"]\n",
    "\n",
    "\n",
    "# fig = plt.figure(figsize=(8, 8))\n",
    "# ax = fig.add_subplot(111)\n",
    "# plt.rcParams['font.size'] = '18'\n",
    "\n",
    "\n",
    "# for (i, name) in enumerate(names):\n",
    "\n",
    "\n",
    "#     MI = np.load(\"Models/%s.npy\" % name)\n",
    "#     plot_MI(600, MI, \"_\", [200, 400], color = colors[i], label = name, savefig = False)\n",
    "\n",
    "\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"I(X;Y)\")\n",
    "# plt.title(\"Learned Mutual Information\")\n",
    "# plt.legend()\n",
    "# # plt.savefig(\"JEC/Plots/MI.pdf\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### PT Plots #####\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.rcParams['font.size'] = '18'\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "predictions = np.array((dnn_predict(test, DNN), efn_predict(test, EFN), pfn_predict(test, PFN), pfn_pid_predict(test, PFN_pid), cms_predict(test, None)))\n",
    "\n",
    "# P_t distribution histograms\n",
    "for i in range(4):\n",
    "    mean, std = np.mean(predictions[i,0]), np.std(predictions[i,0])\n",
    "    plt.hist(predictions[i,0], bins=25, range=[550,850], histtype = 'step', color = colors[i], label = r'$\\hat{y}_{%s}$; %0.1f$\\pm$%0.1f GeV' % (labels[i], mean, std), density=True)\n",
    "    \n",
    "\n",
    "    # Gaussian Fit\n",
    "    temp = predictions[i,0][predictions[i,0] < 850]\n",
    "    temp = predictions[i,0][predictions[i,0] > 550]\n",
    "    x = np.linspace(550, 850, 100)\n",
    "    fit = norm.pdf(x, *(norm.fit(temp)))\n",
    "    plt.plot(x,fit, color = colors[i] ,label = r\"%s Fit; %0.1f $\\pm$ %0.1f\" % (labels[i], *norm.fit(temp) )  )  \n",
    "\n",
    "plt.xlabel(r\"$p_T$ [GeV]\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(r\"Distributions for Gen $p_T \\in [695, 705]$ GeV\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### UNCERTAINTY PLOTS #####\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.rcParams['font.size'] = '18'\n",
    "\n",
    "\n",
    "# P_t uncertainty distribution histograms\n",
    "for i in range(predictions.shape[0]):\n",
    "    mean, std = np.mean(predictions[i,1]), np.std(predictions[i,1])\n",
    "    plt.hist(predictions[i,1], bins=100, range=[15,50], histtype = 'stepfilled', alpha = 0.25, color = colors[i], label = r'$\\sigma_{%s}$; %0.1f$\\pm$%0.1f GeV' % (labels[i], mean, std), density=True)\n",
    "    plt.hist(predictions[i,1], bins=100, range=[15,50], histtype = 'step', color = colors[i], density=True)\n",
    "\n",
    "plt.xlabel(r\"$\\sigma_{p_T}$ [GeV]\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(r\"Distributions for Gen $p_T \\in [695, 705]$ GeV\")\n",
    "# plt.grid()\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.savefig(\"Resolutions.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dijet Loader\n",
    "\n",
    "import energyflow as ef\n",
    "from energyflow.utils import remap_pids\n",
    "\n",
    "def load_data(cache_dir, pt_lower, pt_upper, eta, quality, pad, x_dim = 3, momentum_scale = 250, n = 100000, amount = 1, max_particle_select = None, frac = 1.0, return_pfcs = True):\n",
    "\n",
    "    # Load data\n",
    "    specs = [f'{pt_lower} <= gen_jet_pts <= {pt_upper}', f'abs_gen_jet_eta < {eta}', f'quality >= {quality}']\n",
    "    # specs = [f'{pt_lower} <= jet_pts <= {pt_upper}', f'abs_jet_eta < {eta}', f'quality >= {quality}']\n",
    "    sim = ef.mod.load(*specs, cache_dir = cache_dir, dataset='sim', amount= amount, store_gens = False)\n",
    "\n",
    "    # Gen_pt for Y\n",
    "    Y1 = sim.jets_f[:,sim.gen_jet_pt]\n",
    "    Y = np.zeros((Y1.shape[0], 1), dtype = np.float32 )\n",
    "    Y[:,0] = Y1 / momentum_scale\n",
    "\n",
    "    # Sim_pt for X\n",
    "    X = np.zeros((Y1.shape[0],3), dtype = np.float32)\n",
    "    event_ids = np.zeros((Y1.shape[0],1), dtype = np.int32)\n",
    "    X[:,0] = sim.jets_f[:,sim.jet_pt] / momentum_scale\n",
    "    X[:,1] = sim.jets_f[:,sim.jet_eta]\n",
    "    X[:,2] = sim.jets_f[:,sim.jet_phi]\n",
    "    event_ids = sim.jets_i[:,sim.evn]\n",
    "\n",
    "\n",
    "\n",
    "    # CMS JEC's\n",
    "    C = sim.jets_f[:,sim.jec]\n",
    "\n",
    "    # PFC's\n",
    "    pfcs = sim.particles\n",
    "\n",
    "\n",
    "    pfcs = pfcs[:n]\n",
    "    Y = Y[:n]\n",
    "    X = X[:n]\n",
    "    C = C[:n]\n",
    "    event_ids = event_ids[:n]\n",
    "\n",
    "    # PFC's\n",
    "    dataset = np.zeros( (pfcs.shape[0], pad, x_dim), dtype = np.float32 )\n",
    "    particle_counts = []\n",
    "    if return_pfcs:\n",
    "        for (i, jet) in enumerate(pfcs):\n",
    "            size = min(jet.shape[0], pad)\n",
    "            indices = (-jet[:,0]).argsort()\n",
    "            dataset[i, :size, 0] = jet[indices[:size],0] / momentum_scale\n",
    "            dataset[i, :size, 1] = jet[indices[:size],1]\n",
    "            dataset[i, :size, 2] = jet[indices[:size],2]\n",
    "            if x_dim == 4:\n",
    "                dataset[i, :size, 3] = jet[indices[:size],4] # PID\n",
    "            particle_counts.append(jet.shape[0])\n",
    "        if x_dim == 4:\n",
    "            remap_pids(dataset, pid_i = 3, error_on_unknown = False)\n",
    "\n",
    "        for x in dataset:\n",
    "            mask = x[:,0] > 0\n",
    "            yphi_avg = np.average(x[mask,1:3], weights = x[mask,0], axis = 0)\n",
    "            x[mask,1:3] -= yphi_avg  \n",
    "\n",
    "    particle_counts = np.array(particle_counts)\n",
    "\n",
    "    # Trim and shuffle\n",
    "    if max_particle_select is not None:\n",
    "        dataset = dataset[particle_counts < max_particle_select]\n",
    "        Y = Y[particle_counts < max_particle_select]\n",
    "        X = X[particle_counts < max_particle_select]\n",
    "        C = C[particle_counts < max_particle_select]\n",
    "        particle_counts = particle_counts[particle_counts < max_particle_select]\n",
    "\n",
    "\n",
    "    print(\"X: \", X.shape, X.dtype)\n",
    "    print(\"Y: \", Y.shape, Y.dtype)\n",
    "    print(\"PFCs: \", dataset.shape, dataset.dtype)\n",
    "\n",
    "    if not return_pfcs:\n",
    "        return X, Y, C, particle_counts, event_ids\n",
    "   \n",
    "    print(\"Max # of particles: %d\" % max(particle_counts))\n",
    "    return X, dataset, Y, C, particle_counts, event_ids\n",
    "\n",
    "\n",
    "\n",
    "y_dim = 1\n",
    "x_dim = 3\n",
    "\n",
    "\n",
    "\n",
    "# Dataset Parameters\n",
    "cache_dir = \"/n/holyscratch01/iaifi_lab/rikab/.energyflow\"\n",
    "momentum_scale = 1000\n",
    "n = 10000\n",
    "pad = 150\n",
    "pt_lower, pt_upper = 695, 705\n",
    "eta = 2.4\n",
    "quality = 2\n",
    "\n",
    "# #############################\n",
    "# ########## DATASET ##########\n",
    "# #############################\n",
    "\n",
    "X, pfcs, Y, C, N, ids = load_data(cache_dir, pt_lower, pt_upper, eta, quality, pad, momentum_scale = momentum_scale, n = n, max_particle_select = None, amount = 1, return_pfcs= True)\n",
    "\n",
    "\n",
    "sorted = np.sort(ids)\n",
    "sorted_indices = ids.argsort()\n",
    "print(ids.shape)\n",
    "print(sorted)\n",
    "\n",
    "\n",
    "counter = 0\n",
    "pairs = []\n",
    "N = len(sorted)\n",
    "for (i,id) in enumerate(sorted):\n",
    "    for (j, id2) in enumerate(sorted[(i+1):]):\n",
    "\n",
    "        if id == id2:\n",
    "            counter += 1\n",
    "            pairs.append((i, i+1+j))\n",
    "            break\n",
    "\n",
    "        if id2 > id:\n",
    "            break\n",
    "\n",
    "print(counter / N )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_gen_pts = Y[sorted_indices]\n",
    "sorted_Xs = X[sorted_indices]\n",
    "sorted_Cs = C[sorted_indices]\n",
    "sorted_pfcs =  pfcs[sorted_indices]\n",
    "\n",
    "leading_gen_pts = []\n",
    "subleading_gen_pts = []\n",
    "leading_sim_pts = []\n",
    "subleading_sim_pts = []\n",
    "leading_Cs = []\n",
    "subleading_Cs = []\n",
    "leading_pfcs = []\n",
    "subleading_pfcs = []\n",
    "\n",
    "for pair in pairs:\n",
    "\n",
    "    jet1 = sorted_gen_pts[pair[0]]\n",
    "    jet2 = sorted_gen_pts[pair[1]]\n",
    "\n",
    "    sim_jet1 = sorted_Xs[pair[0]]\n",
    "    sim_jet2 = sorted_Xs[pair[1]]\n",
    "\n",
    "\n",
    "    if jet1 > jet2:\n",
    "        leading_gen_pts.append(jet1)\n",
    "        subleading_gen_pts.append(jet2)\n",
    "\n",
    "        leading_sim_pts.append(sim_jet1)\n",
    "        subleading_sim_pts.append(sim_jet2)\n",
    "        leading_Cs.append(sorted_Cs[pair[0]])\n",
    "        subleading_Cs.append(sorted_Cs[pair[1]])\n",
    "        leading_pfcs.append(sorted_pfcs[pair[0]])\n",
    "        subleading_pfcs.append(sorted_pfcs[pair[1]])\n",
    "    else:\n",
    "        leading_gen_pts.append(jet2)\n",
    "        subleading_gen_pts.append(jet1)\n",
    "\n",
    "        leading_sim_pts.append(sim_jet2)\n",
    "        subleading_sim_pts.append(sim_jet1)\n",
    "        leading_Cs.append(sorted_Cs[pair[1]])\n",
    "        subleading_Cs.append(sorted_Cs[pair[0]])\n",
    "        leading_pfcs.append(sorted_pfcs[pair[1]])\n",
    "        subleading_pfcs.append(sorted_pfcs[pair[0]])\n",
    "\n",
    "leading_gen_pts = np.array(leading_gen_pts)\n",
    "subleading_gen_pts = np.array(subleading_gen_pts)\n",
    "\n",
    "leading_sim_pts = np.array(leading_sim_pts)\n",
    "subleading_sim_pts = np.array(subleading_sim_pts)\n",
    "leading_Cs =np.array(leading_Cs)\n",
    "subleading_Cs=np.array(subleading_Cs)\n",
    "leading_pfcs =np.array(leading_pfcs)\n",
    "subleading_pfcs=np.array(subleading_pfcs)\n",
    "\n",
    "leadings = [leading_sim_pts, leading_pfcs, leading_pfcs]\n",
    "subleadings =[subleading_sim_pts, subleading_pfcs, subleading_pfcs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "\n",
    "\n",
    "Lambda = 22.3 / momentum_scale\n",
    "\n",
    "# CMS Result\n",
    "leading_predicts = leading_sim_pts[:,0] * leading_Cs\n",
    "subleading_predicts = subleading_sim_pts[:,0] * subleading_Cs\n",
    "\n",
    "\n",
    "detector_jet1 = np.copy(leading_predicts)\n",
    "detector_jet2 = np.copy(subleading_predicts)\n",
    "res1 = 1.06*leading_predicts * np.sqrt( 30/(momentum_scale * leading_predicts)**2 + 0.81/(momentum_scale * leading_predicts) + 0.04**2   ) \n",
    "res2 = 1.06*subleading_predicts * np.sqrt( 30/(momentum_scale * subleading_predicts)**2 + 0.81/(momentum_scale * subleading_predicts) + 0.04**2   ) \n",
    "\n",
    "# Math\n",
    "var = np.sqrt(Lambda**2 + res1**2 + res2**2)\n",
    "p1hathat = (detector_jet1 * Lambda**2 + detector_jet1 * res2**2 - detector_jet2 * res1**2) / var**2\n",
    "p2hathat = (detector_jet2 * Lambda**2 - detector_jet1 * res2**2 + detector_jet2 * res1**2) / var**2\n",
    "\n",
    "var1hathat = np.sqrt(1/(1/Lambda**2 + 1/res1**2))\n",
    "var2hathat = np.sqrt(1/(1/Lambda**2 + 1/res2**2))\n",
    "\n",
    "\n",
    "ptothathat = p1hathat + p2hathat\n",
    "vartothathat = np.sqrt(var1hathat**2 + var2hathat**2)\n",
    "\n",
    "\n",
    "concat_stds = momentum_scale * np.concatenate((res1, res2), axis = 0)\n",
    "concat_stds_corrected = momentum_scale * np.concatenate((var1hathat,var2hathat), axis = 0)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.rcParams['font.size'] = '18'\n",
    "\n",
    "plt.hist(concat_stds, bins = 100, range = [15,50], label = \"CMS\", color = \"purple\", alpha = 0.5, density = True)\n",
    "plt.hist(concat_stds_corrected, bins = 100, range = [15,50], label = \"CMS Corr-Imp.\", color = \"purple\", alpha = 0.5, histtype =\"step\", density = True)\n",
    "\n",
    "\n",
    "\n",
    "print(np.mean(concat_stds))\n",
    "\n",
    "\n",
    "for (i,model) in enumerate([DNN,EFN, PFN]):\n",
    "    detector_jet1, res1 = model.eval(leadings[i])\n",
    "    detector_jet2, res2 = model.eval(subleadings[i])\n",
    "\n",
    "\n",
    "    detector_jet1 = leading_predicts\n",
    "    detector_jet2 = subleading_predicts\n",
    "    # res1 = leading_stds\n",
    "    # res2 = subleading_stds\n",
    "\n",
    "    # Math\n",
    "    var = np.sqrt(Lambda**2 + res1**2 + res2**2)\n",
    "    p1hathat = (detector_jet1 * Lambda**2 + detector_jet1 * res2**2 - detector_jet2 * res1**2) / var**2\n",
    "    p2hathat = (detector_jet2 * Lambda**2 - detector_jet1 * res2**2 + detector_jet2 * res1**2) / var**2\n",
    "\n",
    "    var1hathat = np.sqrt(1/(1/Lambda**2 + 1/res1**2))\n",
    "    var2hathat = np.sqrt(1/(1/Lambda**2 + 1/res2**2))\n",
    "\n",
    "\n",
    "    ptothathat = p1hathat + p2hathat\n",
    "    vartothathat = np.sqrt(var1hathat**2 + var2hathat**2)\n",
    "\n",
    "\n",
    "    concat_stds = momentum_scale  * np.concatenate((res1, res2), axis = 0)\n",
    "    concat_stds_corrected = momentum_scale * np.concatenate((var1hathat,var2hathat), axis = 0)\n",
    "\n",
    "    plt.hist(concat_stds, bins = 100, range = [15,50], label = \"GA %s\" % labels[i], color = colors[i], alpha = 0.5, density = True)\n",
    "    plt.hist(concat_stds_corrected, bins = 100, range = [15,50], label = \"GA %s Corr-Imp.\" % labels[i], color = colors[i], alpha = 0.5, histtype =\"step\", density = True, lw = 3)\n",
    "\n",
    "\n",
    "plt.legend(title = \"$\\Lambda = %.1f$ GeV\" % (Lambda * 1000))\n",
    "plt.xlabel(r\"$\\sigma_{p_T}$ [GeV]\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(r\"Distributions for Gen $p_T \\in [695, 705]$ GeV\")\n",
    "\n",
    "plt.savefig(\"Correlation_Improved_Resolutions.pdf\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dijet Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in GEANT4 test set\n",
    "\n",
    "\n",
    "def load_data(cache_dir, pt_lower, pt_upper, eta, quality, pad, x_dim = 3, momentum_scale = 250, n = 100000, amount = 1, max_particle_select = None, frac = 1.0, return_pfcs = True):\n",
    "\n",
    "    # Load data\n",
    "    specs = [f'{pt_lower} <= gen_jet_pts <= {pt_upper}', f'abs_jet_eta < {eta}', f'quality >= {quality}']\n",
    "    sim = ef.mod.load(*specs, cache_dir = cache_dir, dataset='sim', amount= amount)\n",
    "\n",
    "    # Gen_pt for Y\n",
    "    Y1 = sim.jets_f[:,sim.gen_jet_pt]\n",
    "    Y = np.zeros((Y1.shape[0], 1), dtype = np.float32 )\n",
    "    Y[:,0] = Y1 / momentum_scale\n",
    "\n",
    "    # Sim_pt for X\n",
    "    X = np.zeros((Y1.shape[0],3), dtype = np.float32)\n",
    "    X[:,0] = sim.jets_f[:,sim.jet_pt] / momentum_scale\n",
    "    X[:,1] = sim.jets_f[:,sim.jet_eta]\n",
    "    X[:,2] = sim.jets_f[:,sim.jet_phi]\n",
    "    X[:,3] = sim.jets_f[:,sim.jet_m] / momentum_scale\n",
    "\n",
    "\n",
    "\n",
    "    # CMS JEC's\n",
    "    C = sim.jets_f[:,sim.jec]\n",
    "\n",
    "    # PFC's\n",
    "    pfcs = sim.particles\n",
    "\n",
    "    # Shuffle and trim\n",
    "    shuffle_indices = np.random.choice(np.arange(pfcs.shape[0]), size = int(pfcs.shape[0] * frac), replace=False)\n",
    "    pfcs = pfcs[shuffle_indices]\n",
    "    Y = Y[shuffle_indices]\n",
    "    X = X[shuffle_indices]\n",
    "    C = C[shuffle_indices]\n",
    "\n",
    "    pfcs = pfcs[:n]\n",
    "    Y = Y[:n]\n",
    "    X = X[:n]\n",
    "    C = C[:n]\n",
    "\n",
    "    # PFC's\n",
    "    dataset = np.zeros( (pfcs.shape[0], pad, x_dim), dtype = np.float32 )\n",
    "    particle_counts = []\n",
    "    if return_pfcs:\n",
    "        for (i, jet) in enumerate(pfcs):\n",
    "            size = min(jet.shape[0], pad)\n",
    "            indices = (-jet[:,0]).argsort()\n",
    "            dataset[i, :size, 0] = jet[indices[:size],0] / momentum_scale\n",
    "            dataset[i, :size, 1] = jet[indices[:size],1]\n",
    "            dataset[i, :size, 2] = jet[indices[:size],2]\n",
    "            if x_dim == 4:\n",
    "                dataset[i, :size, 3] = jet[indices[:size],4] # PID\n",
    "            particle_counts.append(jet.shape[0])\n",
    "        if x_dim == 4:\n",
    "            remap_pids(dataset, pid_i = 3, error_on_unknown = False)\n",
    "\n",
    "        for x in dataset:\n",
    "            mask = x[:,0] > 0\n",
    "            yphi_avg = np.average(x[mask,1:3], weights = x[mask,0], axis = 0)\n",
    "            x[mask,1:3] -= yphi_avg  \n",
    "\n",
    "    particle_counts = np.array(particle_counts)\n",
    "\n",
    "    # Trim and shuffle\n",
    "    if max_particle_select is not None:\n",
    "        dataset = dataset[particle_counts < max_particle_select]\n",
    "        Y = Y[particle_counts < max_particle_select]\n",
    "        X = X[particle_counts < max_particle_select]\n",
    "        C = C[particle_counts < max_particle_select]\n",
    "        particle_counts = particle_counts[particle_counts < max_particle_select]\n",
    "\n",
    "    shuffle_indices = np.random.choice(np.arange(dataset.shape[0]), size = int(dataset.shape[0] * frac), replace=False)\n",
    "\n",
    "    print(\"X: \", X.shape, X.dtype)\n",
    "    print(\"Y: \", Y.shape, Y.dtype)\n",
    "    print(\"PFCs: \", dataset.shape, dataset.dtype)\n",
    "\n",
    "    if not return_pfcs:\n",
    "        return X, Y, C, particle_counts\n",
    "   \n",
    "    print(\"Max # of particles: %d\" % max(particle_counts))\n",
    "    return X, dataset, Y, C, particle_counts\n",
    "\n",
    "\n",
    "\n",
    "sim10 = ef.mod.load(dataset='sim',subdatasets=[\"SIM1000_Jet300_pT375-infGeV\"])\n",
    "gen10 = ef.mod.load(dataset='gen',subdatasets=[\"GEN1000_pT375-infGeV\"])\n",
    "\n",
    "sim14 = ef.mod.load(dataset='sim',subdatasets=[\"SIM1400_Jet300_pT375-infGeV\"])\n",
    "sim18 = ef.mod.load(dataset='sim',subdatasets=[\"SIM1800_Jet300_pT375-infGeV\"])\n",
    "\n",
    "gen14 = ef.mod.load(dataset='gen',subdatasets=[\"GEN1400_pT375-infGeV\"])\n",
    "gen18 = ef.mod.load(dataset='gen',subdatasets=[\"GEN1800_pT375-infGeV\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TOOD: Convert Ben's code to my code.\n",
    "\n",
    "#Truth\n",
    "    pT1g = simjets[2*i,8]\n",
    "    pT2g = simjets[2*i+1,8]\n",
    "    \n",
    "    y1g = simjets[2*i,9]\n",
    "    y2g = simjets[2*i+1,9]\n",
    "    \n",
    "    phi1g = simjets[2*i,10]\n",
    "    phi2g = simjets[2*i+1,10]\n",
    "    \n",
    "    m1g = simjets[2*i,11]\n",
    "    m2g = simjets[2*i+1,11]\n",
    "    \n",
    "    ET1g = np.sqrt(pT1g**2+m1g**2)\n",
    "    ET2g = np.sqrt(pT2g**2+m2g**2)\n",
    "    \n",
    "    mJJg = m1g**2+m2g**2+2*(ET1g*ET2g*np.cosh(y1g-y2g)-pT1g*pT2g*np.cos(phi1g-phi2g))\n",
    "    mjjsg+=[mJJg**0.5]\n",
    "    mjjsg+=[mJJg**0.5]\n",
    "    pTsg+=[pT1g]\n",
    "    pTsg+=[pT2g]\n",
    "    etasg+=[y1g]\n",
    "    etasg+=[y2g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbac56038863e62075282f2012891c4bcee253630f93c34a839c88dd5a02bed8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
